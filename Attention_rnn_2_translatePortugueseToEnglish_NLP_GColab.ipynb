{"cells":[{"cell_type":"markdown","metadata":{"id":"p4z1Axzf4Vwf"},"source":["# **Attention - Tradutor Português para Inglês**\n","\n","- Neste notebook vamos criar um algoritmo capaz de traduzir sentenças do Inglês para o Português.\n","- O código é o mesmo da tradução Inglês-Português, com poucas modificações pontuais.\n","- Sendo assim, apenas o código é mostrado. Para verificar a teoria, comentários e explicações do código, veja \"Attention_rnn_1_translateEnglishToPortuguese_NLP_GColab.ipynb\".\n","\n","## O trecho no qual é mostrada a inversão do tradutor Inglês-Português para Português-Inglês é comentada e explicada abaixo."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxNgM9E4vwLF","outputId":"bb79485f-512f-4893-ba5b-b14413d5e91d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"]}],"source":["#Garantir que está usando a versão mais recente de Keras\n","! pip install keras --upgrade"]},{"cell_type":"markdown","metadata":{"id":"62LiKVE8n-6e"},"source":["# **Attention**\n","\n","# **Many-to-One Task**\n"]},{"cell_type":"markdown","metadata":{"id":"u22w3BFiOveA"},"source":["# **Montar o Google Drive localmente - Autorizar conexão do Google Colab aos arquivos do Google Drive**\n","\n","O exemplo abaixo mostra como montar o Google Drive no seu ambiente de execução usando um código de autorização, além de como gravar e ler arquivos nele. Depois de executado, você verá o novo arquivo &#40;<code>foo.txt</code>&#41; no <a href=\"https://drive.google.com/\">https://drive.google.com/</a>.\n","\n","Isto permite somente ler, gravar e mover arquivos. Para modificar de maneira programática as configurações de compartilhamento ou outros metadados, use uma das opções abaixo.\n","\n","<strong>Observação:</strong> ao usar o botão \"Montar Drive\" no navegador de arquivos, não é necessário usar nenhum código de autenticação para notebooks que tenham sido editados somente pelo usuário atual."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWSJpsyKqHjH","outputId":"be1500b8-2b05-45bf-9acf-a73b58ba3df7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#Esta célula é utilizada para conectar à conta do Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"sLmPin6ig-eO"},"source":["# **Importar bibliotecas para análise**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5LC3b1ag8dX"},"outputs":[],"source":["# https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n","from __future__ import print_function, division\n","from builtins import range, input\n","# Note: you may need to update your version of future\n","# sudo pip install -U future\n","\n","import os, sys\n","\n","from keras.models import Model\n","from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n","  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import keras.backend as K\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","try:\n","  import keras.backend as K\n","  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n","    from keras.layers import CuDNNLSTM as LSTM\n","    from keras.layers import CuDNNGRU as GRU\n","except:\n","  pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaYt0T4DTmGm"},"outputs":[],"source":["# make sure we do softmax over the time axis\n","# expected shape is N x T x D\n","# note: the latest version of Keras allows you to pass in axis arg\n","def softmax_over_time(x):\n","  assert(K.ndim(x) > 2)\n","  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n","  s = K.sum(e, axis=1, keepdims=True)\n","  return e / s"]},{"cell_type":"markdown","metadata":{"id":"LhqIspfRhvS4"},"source":["# **Configurações das redes neurais e do processamento de texto**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eI_tusKJh0L4"},"outputs":[],"source":["# config\n","BATCH_SIZE = 64\n","EPOCHS = 30\n","LATENT_DIM = 400\n","LATENT_DIM_DECODER = 400 # idea: make it different to ensure things all fit together properly!\n","NUM_SAMPLES = 4000 #20000 is too much for both AWS and Colab available RAMs\n","MAX_SEQUENCE_LENGTH = 100\n","MAX_NUM_WORDS = 20000\n","EMBEDDING_DIM = 100"]},{"cell_type":"markdown","metadata":{"id":"ilCNGEF8VpeW"},"source":["**`BATCH_SIZE`**: quantos dados são usados em cada forward and backward pass. Se temos 3200 dados e o batch size é 32, ocorrem 100 passagens de 32 dados em cada época."]},{"cell_type":"markdown","metadata":{"id":"2MPJwp59WPpn"},"source":["# **Criação das listas que armazenarão as sentenças a serem traduzidas**\n","\n","Como visto, no treinamento utilizamos a abordagem do Teacher Forcing:\n","- Temos as sequências (sentenças) de input a serem traduzidas. O início da sentença é assinalado pelo token `<SOS>`.\n","- As sentenças são armazenadas de forma consecutiva em uma lista, chamada `input_texts`. Assim, cada token `<SOS>` indica o apêndice de um novo elemento a esta lista.\n","- Para treinarmos o modelo de redes neurais, temos uma série de sentenças para as quais conhecemos a tradução correta (os targets). \n","- Criamos, então, uma nova lista, chamada `target_texts`, que armazenará sequencialmente as sentenças traduzidas.\n","- Repare que as listas `input_texts` e `target_texts` possuem índices correspondentes: a tradução do elemento (sentença) de índice i de `input_texts`, `input_texts[i]`, é o elemento (sentença) de índice i de `target_texts`, `target_texts[i]`.\n","- A indexação das listas começa em zero. Assim, se a lista possui n elementos, seus índices i são tais que 0 ≤ i ≤ (n-1).\n","\n","No teacher forcing, os inputs de uma unidade recorrente são: os estados h e c obtidos como saídas da unidade anterior; e os targets (sentenças traduzidas, com tradução validada).\n","- Assim, ainda que o algoritmo tenha traduzido alguma palavra de forma incorreta, ele utilizará a palavra correta para tentar prever a tradução da palavra seguinte. \n","- Com esta correção, o treinamento não é prejudicado caso uma palavra tenha sido prevista de forma equivocada.\n","- Entretanto, o teacher forcing exige que haja um offset de uma unidade entre a palavra que a unidade irá prever e a palavra target utilizada como input.\n","- **De outra forma: o input de uma unidade será a palavra que a unidade anterior deveria ter previsto** (ainda que a previsão do algoritmo tenha sido equivocada).\n","- Sem este offset, ou seja, se a unidade recorrente fosse alimentada exatamente com a palavra target que ela deveria prever, ela seria ensinada a simplesmente copiar o seu input no seu output, algo sem utilidade.\n","- Assim, criamos a lista `target_texts_inputs` para armazenar as sequências de target com o offset de 1 unidade."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22umOYV9j0Ef"},"outputs":[],"source":["# Where we will store the data\n","input_texts = [] # sentence in original language\n","target_texts = [] # sentence in target language\n","target_texts_inputs = [] # sentence in target language offset by 1"]},{"cell_type":"markdown","metadata":{"id":"8ktkcpAh-Uyc"},"source":["# **Inverter o tradutor Inglês-Português para o Português-Inglês**\n","- Basta fazer a troca: o que seria armazenado na lista de input (frases em inglês) será armazenado nas listas de target.\n","- O que seria armazenado nas listas de target (frases em português) será armazenado nas listas de input.\n","\n","# **Para isso, basta trocar a ordem de armazenamento do resultante do split da linha:**\n","\n","Em `input_text, translation, *rest = line.rstrip().split('\\t')`\n","\n","A primeira porção antes da quebra de linha é usada como input e a segunda como target e tradução. Como o dicionário é inglês/português, a primeira porção é em Inglês.\n","\n","Sendo assim, mudamos esta linha para:\n","\n","`translation, input_text, *rest = line.rstrip().split('\\t')`\n","\n","Para que o Inglês (primeira parte) se tornar a língua traduzida."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3Ao2fgMOfPS","outputId":"6f71e5dd-acda-4b3c-c5e9-1e16358affba"},"outputs":[{"name":"stdout","output_type":"stream","text":["num samples: 4000\n"]}],"source":["#CARREGAR ARQUIVO COM O DICIONÁRIO\n","#Este arquivo contém frases traduzidas de um idioma para outro, e cuja tradução foi validada.\n","#Assim, este arquivo possui tanto inputs (frases a serem traduzidas) quanto os targets \n","#(tradução que o algoritmo deve aprender)\n","\n","# load in the data\n","# download the data at: http://www.manythings.org/anki/\n","t = 0\n","for line in open('portuguese_english_dict.txt'):\n","  # only keep a limited number of samples\n","  t += 1\n","  if t > NUM_SAMPLES:\n","    break\n","\n","  # input and target are separated by tab\n","  if '\\t' not in line:\n","    continue\n","\n","  # split up the input and translation\n","  #input_text, translation, *rest = line.rstrip().split('\\t')\n","  #The line above makes the first part of the line prior to the break to be used as\n","  #input. Since this dictionary is English-Portuguese, it results into English to\n","  #Portuguese translation. To obtain the Portuguese to English, we must take the\n","  #first part as input. To do so, we simply invert the order of selection:\n","  \n","  translation, input_text, *rest = line.rstrip().split('\\t')\n","\n","  # make the target input and output\n","  # recall we'll be using teacher forcing\n","  target_text = translation + ' <eos>'\n","  target_text_input = '<sos> ' + translation\n","\n","  input_texts.append(input_text)\n","  target_texts.append(target_text)\n","  target_texts_inputs.append(target_text_input)\n","print(\"num samples:\", len(input_texts))"]},{"cell_type":"markdown","metadata":{"id":"9RYyO1y2fHGy"},"source":["# **Aplicar o método keras.tokenizer aos inputs para conversão das sentenças em números inteiros**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PKdtjKzHZwDa"},"outputs":[],"source":["# tokenize the inputs\n","tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer_inputs.fit_on_texts(input_texts)\n","input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"]},{"cell_type":"markdown","metadata":{"id":"7nnU3cv_zLle"},"source":["# **Associar cada palavra a uma linha (vetor de palavras) do word embedding**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LX2x_gMiJDdY","outputId":"3397ce41-6d18-4988-c35e-4bcfd4e5bf4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1872 unique input tokens.\n"]}],"source":["# get the word to index mapping for input language\n","word2idx_inputs = tokenizer_inputs.word_index\n","print('Found %s unique input tokens.' % len(word2idx_inputs))"]},{"cell_type":"markdown","metadata":{"id":"3c3ZXakVf4uO"},"source":["# **Caracterização das sequências de texto obtidas e convertidas em inteiros**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iu-xz25LO5Ty"},"outputs":[],"source":["# determine maximum length input sequence\n","max_len_input = max(len(s) for s in input_sequences)"]},{"cell_type":"markdown","metadata":{"id":"c9mAQq7ASEhf"},"source":["# **Repetir as etapas anteriores para os outputs (tokenização, mapeamento e caracterização) para os outputs**\n","\n","- O algoritmo para tradução lida com dois idiomas diferentes.\n","- Isto significa que temos 2 vocabulários distintos, um no Encoder (língua original), e outro no Decoder (idioma-alvo).\n","\n","### **Como temos dois vocabulários, é necessário criar 2 tokenizers, um para cada idioma. O primeiro é aplicado às sentenças do idioma original, o segundo às do idioma target.**\n","\n","- Isto também leva à necessidade de 2 mapeamentos word2idx distintos, cada um com suas próprias variáveis descritivas (total de palavras e máximo comprimento de sentença)."]},{"cell_type":"markdown","metadata":{"id":"ZMCXuPHWSTHm"},"source":["# **Tokenização**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tondq5SIJLry"},"outputs":[],"source":["# tokenize the outputs\n","# don't filter out special characters\n","# otherwise <sos> and <eos> won't appear\n","tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n","tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n","target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n","target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"]},{"cell_type":"markdown","metadata":{"id":"-H_6LCLiV_hd"},"source":["# **Mapeamento (dicionário word2idx das saídas)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKZWevVzzdWc","outputId":"2b4c5aca-1811-4f3e-eabf-fd108fca92c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1380 unique output tokens.\n"]}],"source":["# get the word to index mapping for output language\n","word2idx_outputs = tokenizer_outputs.word_index\n","print('Found %s unique output tokens.' % len(word2idx_outputs))"]},{"cell_type":"markdown","metadata":{"id":"nvrGm8LRWH0O"},"source":["Este dicionário será responsável por converter os valores numéricos obtidos como saída do decoder em palavras, de modo a gerar as sentenças traduzidas."]},{"cell_type":"markdown","metadata":{"id":"N_fURxSRWSTU"},"source":["# **Caracterização: número de palavras e máximo comprimento de sentença**\n","\n","- Estas variáveis devem ser calculadas e armazenadas para uso posterior."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hC58TAzuJRiW"},"outputs":[],"source":["# store number of output words for later\n","# remember to add 1 since indexing starts at 1\n","num_words_output = len(word2idx_outputs) + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDGpd05nJUsp"},"outputs":[],"source":["# determine maximum length output sequence\n","max_len_target = max(len(s) for s in target_sequences)"]},{"cell_type":"markdown","metadata":{"id":"Vn38u-CS0oJV"},"source":["# **Limitar comprimento das sequências de texto com o método pad_sequences**"]},{"cell_type":"markdown","metadata":{"id":"-SrEG6z3e7dJ"},"source":["# **Padding do Encoder**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WVLgpwr0z2X","outputId":"e1d45f24-7c6a-4c8a-cb22-7921d2b1a9d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder_data.shape: (4000, 8)\n","encoder_data[0]: [ 0  0  0  0  0  0  0 32]\n"]}],"source":["## pad the sequences\n","encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n","print(\"encoder_data.shape:\", encoder_inputs.shape)\n","print(\"encoder_data[0]:\", encoder_inputs[0])"]},{"cell_type":"markdown","metadata":{"id":"9tL15pyafIM6"},"source":["# **Padding do Decoder**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMORcsB5Jgmg","outputId":"910c3c5e-6a34-4665-eacc-021417a7b07a"},"outputs":[{"name":"stdout","output_type":"stream","text":["decoder_data[0]: [ 2 60  0  0  0]\n","decoder_data.shape: (4000, 5)\n"]}],"source":["decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n","print(\"decoder_data[0]:\", decoder_inputs[0])\n","print(\"decoder_data.shape:\", decoder_inputs.shape)\n","\n","decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"]},{"cell_type":"markdown","metadata":{"id":"QplYu8hQ1A-s"},"source":["Esta etapa é particularmente importante porque a biblioteca **Keras trabalha com sequências de dimensões constantes**.\n","- O formato do tensor de dados representa a dimensão da matriz (N x T) obtida. \n","- Note que, como desejamos que o algoritmo aprenda a traduzir sentenças de diversos comprimentos, não limitamos a `MAX_SEQUENCE_LENGTH = 100` o máximo comprimento da sequência de textos, como em exemplos anteriores.\n","- N = contagem de elementos;\n","- T será o máximo comprimento permitido para o vetor de palavras (máximo possível de colunas)."]},{"cell_type":"markdown","metadata":{"id":"0d6Xy9QThLJQ"},"source":["# **Vamos criar um dicionário vazio, chamado word2vec** \n","Este dicionário armazenará os dados já pré-configurados, i.e., palavras que já foram convertidas em vetores numéricos, e que estão disponíveis nas bases glove.6B.\n","\n","- O comprimento dos vetores de palavras será o definido e armazenado em EMBEDDING_DIM.\n","- O dicionário possui como estrutura: a palavra como a chave (key); e o vetor de palavras (word vector) como o valor correspondente.\n","- A nomenclatura word2vec vem de \"word pointing to vector\".\n","- Os arquivos glove.6B consistem em txt contendo a cada linha uma palavra seguida dos valores das componentes dos vetores, separados por espaços em branco.\n","- Assim, nós: 1) carregamos uma linha; 2) dividimos (split) as linhas em tokens; 3) tomamos o primeiro token como sendo a palavra; 4) tomamos os demais tokens como o vetor; 5) convertemos o vetor em um NumPy array; 6) e, por fim, salvamos cada array no nosso dicionário."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MEIQjDghbd4","outputId":"87460836-9b3e-493f-df69-15ed71a3351b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading word vectors...\n","Found 400000 word vectors.\n"]}],"source":["# store all the pre-trained word vectors\n","print('Loading word vectors...')\n","word2vec = {}\n","with open(os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n","  # is just a space-separated text file in the format:\n","  # word vec[0] vec[1] vec[2] ...\n","  for line in f:\n","    values = line.split()\n","    word = values[0]\n","    vec = np.asarray(values[1:], dtype='float32')\n","    word2vec[word] = vec\n","print('Found %s word vectors.' % len(word2vec))"]},{"cell_type":"markdown","metadata":{"id":"UxDgi89rCrAb"},"source":["# **Pré-carregar a matriz de incorporação (\"embedding matrix\") que será utilizada pela rede neural**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwcfLgYb21qP","outputId":"d68707b5-df9e-4680-86c1-06fdea59392e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Filling pre-trained embeddings...\n"]}],"source":["# prepare embedding matrix\n","print('Filling pre-trained embeddings...')\n","num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)"]},{"cell_type":"markdown","metadata":{"id":"WqRrzMIHA1qJ"},"source":["# **Criação da matriz embedding**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rB9BnSZbDy3A"},"outputs":[],"source":["embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n","\n","for word, i in word2idx_inputs.items():\n","  if i < MAX_NUM_WORDS:\n","    embedding_vector = word2vec.get(word)\n","    if embedding_vector is not None:\n","      # words not found in embedding index will be all zeros.\n","      embedding_matrix[i] = embedding_vector"]},{"cell_type":"markdown","metadata":{"id":"rBR_205WsmDT"},"source":["# **Criação de versão one-hot dos targets**\n","\n","A função de \"sparse cross-entropy\" de Keras não funcionará se o input for uma sequência.\n","- Isto não era problema nos exemplos anteriores porque possuíamos apenas um target por input.\n","- Porém, agora **temos dois targets por input: cada amostra nos fornece uma sequência completa de targets**.\n","\n","Como a \"sparse cross-entropy\" não foi projetada para este caso, é possível construir a própria função de perda."]},{"cell_type":"markdown","metadata":{"id":"YV3J8CafAfeZ"},"source":["Criação da matriz nula:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYrXxtEwKNfA"},"outputs":[],"source":["# create targets, since we cannot use sparse\n","# categorical cross entropy when we have sequences\n","decoder_targets_one_hot = np.zeros(\n","  (\n","    len(input_texts),\n","    max_len_target,\n","    num_words_output\n","  ),\n","  dtype='float32'\n",")"]},{"cell_type":"markdown","metadata":{"id":"-I3NAfPUAiH5"},"source":["Assinalar valores 1 aos elementos especificados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2XsVMs3KYNl"},"outputs":[],"source":["# assign the values\n","for i, d in enumerate(decoder_targets):\n","  for t, word in enumerate(d):\n","    if word > 0:\n","      decoder_targets_one_hot[i, t, word] = 1"]},{"cell_type":"markdown","metadata":{"id":"oYYDYvs_9a7C"},"source":["Note que primeiro criamos uma matriz apenas com elementos nulos (np.zeros).\n","- A seguir, fornecemos o valor 1 apenas aos elementos especificados, de modo a diferenciá-los uns dos outros (ou seja, de modo a realizar o encoding destes elementos)."]},{"cell_type":"markdown","metadata":{"id":"jo3lUR33FmFa"},"source":["# **Construção e avaliação da RNN**"]},{"cell_type":"markdown","metadata":{"id":"bqJDGfflnC7x"},"source":["# **Criação da camada de embedding**"]},{"cell_type":"markdown","metadata":{"id":"o-A-zvQZnKkO"},"source":["A criação da camada de embedding consiste em simplesmente criar um objeto do tipo \"**Embedding**\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PLJdSb0BRkS"},"outputs":[],"source":["# create embedding layer\n","embedding_layer = Embedding(\n","  num_words,\n","  EMBEDDING_DIM,\n","  weights=[embedding_matrix],\n","  input_length=max_len_input,\n","  # trainable=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"cMUJb5K7pcel"},"source":["# **Construção do restante do modelo de redes neurais recorrentes (RNNs)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfvKBK3ApqpI"},"outputs":[],"source":["##### build the model #####\n","\n","# Set up the encoder - simple!\n","encoder_inputs_placeholder = Input(shape=(max_len_input,))\n","x = embedding_layer(encoder_inputs_placeholder)\n","encoder = Bidirectional(LSTM(\n","  LATENT_DIM,\n","  return_sequences=True,\n","  # dropout=0.5 # dropout not available on gpu\n","))\n","encoder_outputs = encoder(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv1I8b70Ktmg"},"outputs":[],"source":["# Set up the decoder - not so simple\n","decoder_inputs_placeholder = Input(shape=(max_len_target,))\n","\n","# this word embedding will not use pre-trained vectors\n","# although you could\n","decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n","decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjuyKFhpXTiI"},"outputs":[],"source":["######### Attention #########\n","# Attention layers need to be global because\n","# they will be repeated Ty times at the decoder\n","attn_repeat_layer = RepeatVector(max_len_input)\n","attn_concat_layer = Concatenate(axis=-1)\n","attn_dense1 = Dense(10, activation='tanh')\n","attn_dense2 = Dense(1, activation=softmax_over_time)\n","attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4a3QW2ZXKwy"},"outputs":[],"source":["def one_step_attention(h, st_1):\n","  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n","  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n"," \n","  # copy s(t-1) Tx times\n","  # now shape = (Tx, LATENT_DIM_DECODER)\n","  st_1 = attn_repeat_layer(st_1)\n","\n","  # Concatenate all h(t)'s with s(t-1)\n","  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n","  x = attn_concat_layer([h, st_1])\n","\n","  # Neural net first layer\n","  x = attn_dense1(x)\n","\n","  # Neural net second layer with special softmax over time\n","  alphas = attn_dense2(x)\n","\n","  # \"Dot\" the alphas and the h's\n","  # Remember a.dot(b) = sum over a[t] * b[t]\n","  context = attn_dot([alphas, h])\n","\n","  return context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSWe8wSyXgI5"},"outputs":[],"source":["# define the rest of the decoder (after attention)\n","decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","\n","initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n","initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n","context_last_word_concat_layer = Concatenate(axis=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JsPdjI3XlQ5"},"outputs":[],"source":["# Unlike previous seq2seq, we cannot get the output\n","# all in one step\n","# Instead we need to do Ty steps\n","# And in each of those steps, we need to consider\n","# all Tx h's\n","\n","# s, c will be re-assigned in each iteration of the loop\n","s = initial_s\n","c = initial_c\n","\n","# collect outputs in a list at first\n","outputs = []"]},{"cell_type":"markdown","metadata":{"id":"SgYJw_6J788q"},"source":["No caso do decoder, precisamos dos dois argumentos `return_sequences=True` e `return_state=True`, garantindo tanto o registro das saídas quanto dos estados a cada tempo.\n","\n","Assim como visto para a geração de poemas, e**ste registro dos estados não é necessário para o treinamento, mas será para a realização de previsões. Nas previsões, utilizaremos o mesmo modelo de redes neurais com pesos já treinados, razão pela qual devemos definir estes parâmetros antecipadamente com o valor True**.\n","\n","Como não é necessário armazenar os estados neste momento, podemos utilizar o sinal `_` em:\n","\n","```\n","decoder_outputs, _, _ = decoder_lstm(\n","```\n","Com este sinal, não geramos o erro de exceção associado ao chamamento de menos variáveis à esquerda do que a quantidade de saídas à direita. Porém, as saídas à direita que seriam armazenadas pelo objeto substituído por `_` são apagadas da memória.\n","- Com isso, economizamos memória, já que não necessitamos armazenar estes estados durante o treinamento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hks1bqPmYnbw"},"outputs":[],"source":["for t in range(max_len_target): # Ty times\n","  # get the context using attention\n","  context = one_step_attention(encoder_outputs, s)\n","\n","  # we need a different layer for each time step\n","  selector = Lambda(lambda x: x[:, t:t+1])\n","  xt = selector(decoder_inputs_x)\n","  \n","  # combine \n","  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n","\n","  # pass the combined [context, last word] into the LSTM\n","  # along with [s, c]\n","  # get the new [s, c] and output\n","  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n","\n","  # final dense layer to get next word prediction\n","  decoder_outputs = decoder_dense(o)\n","  outputs.append(decoder_outputs)\n","\n","# 'outputs' is now a list of length Ty\n","# each element is of shape (batch size, output vocab size)\n","# therefore if we simply stack all the outputs into 1 tensor\n","# it would be of shape T x N x D\n","# we would like it to be of shape N x T x D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8x50uCe_XwFA"},"outputs":[],"source":["def stack_and_transpose(x):\n","  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n","  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n","  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n","  \n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zrco9kgPXzBx"},"outputs":[],"source":["# make it a layer\n","stacker = Lambda(stack_and_transpose)\n","outputs = stacker(outputs)"]},{"cell_type":"markdown","metadata":{"id":"DCGAMPaCwIYn"},"source":["# **Criação de um objeto do modelo (\"model object\")**\n","\n","Agora que concluímos a construção do modelo, podemos assinalar ele a um objeto que armazenará as suas principais informações.\n","\n","- **A função construtora (\"constructor\") deste objeto utiliza como primeiro argumento o input, e a saída (\"output\") como segundo argumento**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTvEzGBpwyQh"},"outputs":[],"source":["# create the model\n","model = Model(\n","  inputs=[\n","    encoder_inputs_placeholder,\n","    decoder_inputs_placeholder,\n","    initial_s, \n","    initial_c,\n","  ],\n","  outputs=outputs\n",")"]},{"cell_type":"markdown","metadata":{"id":"KchbpYrnw0Yu"},"source":["Note que o objeto que armazena o modelo foi denominado \"model\"."]},{"cell_type":"markdown","metadata":{"id":"1DzHEHwaV8-j"},"source":["# **Função de perda e métrica de precisão**\n","\n","Como visto, podemos definir funções de perda e de precisão adaptadas para o caso particular, como feito a seguir.\n","- Uma vez definidas estas funções, elas podem ser evocadas normalmente pelo processo de treinamento.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4PisNObK4uQ"},"outputs":[],"source":["def custom_loss(y_true, y_pred):\n","  # both are of shape N x T x K\n","  mask = K.cast(y_true > 0, dtype='float32')\n","  out = mask * y_true * K.log(y_pred)\n","  return -K.sum(out) / K.sum(mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCU4xaFtK5bH"},"outputs":[],"source":["def acc(y_true, y_pred):\n","  # both are of shape N x T x K\n","  targ = K.argmax(y_true, axis=-1)\n","  pred = K.argmax(y_pred, axis=-1)\n","  correct = K.cast(K.equal(targ, pred), dtype='float32')\n","\n","  # 0 is padding, don't include those\n","  mask = K.cast(K.greater(targ, 0), dtype='float32')\n","  n_correct = K.sum(mask * correct)\n","  n_total = K.sum(mask)\n","  return n_correct / n_total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qomVvnpfx1YW"},"outputs":[],"source":["# compile the model\n","model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n","# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n","\n","# train the model\n","z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]"]},{"cell_type":"markdown","metadata":{"id":"TCUREOy1yHiO"},"source":["# **Treinar o modelo**\n","\n","- Utilizamos o método **.fit** para treinar o modelo.\n","- **O modelo treinado ficará armazenado no objeto r** definido a seguir."]},{"cell_type":"markdown","metadata":{"id":"fYY4NRUxDNDR"},"source":["No trecho a seguir, o modelo é representado por `model`. \n","- `r` representa um dicionário contendo diversas informações históricas a respeito do processo de treinamento do modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wutstPIgyDid","outputId":"0669478b-eab4-4cf6-93b4-dfaebc3de994"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","50/50 [==============================] - 28s 354ms/step - loss: 5.0084 - acc: 0.3262 - val_loss: 4.9681 - val_acc: 0.3303\n","Epoch 2/30\n","50/50 [==============================] - 15s 293ms/step - loss: 3.9750 - acc: 0.3591 - val_loss: 4.7805 - val_acc: 0.3441\n","Epoch 3/30\n","50/50 [==============================] - 16s 315ms/step - loss: 3.6410 - acc: 0.4002 - val_loss: 4.8136 - val_acc: 0.3448\n","Epoch 4/30\n","50/50 [==============================] - 15s 302ms/step - loss: 3.3317 - acc: 0.4284 - val_loss: 4.6727 - val_acc: 0.3715\n","Epoch 5/30\n","50/50 [==============================] - 15s 293ms/step - loss: 3.0494 - acc: 0.4588 - val_loss: 4.5166 - val_acc: 0.3904\n","Epoch 6/30\n","50/50 [==============================] - 15s 292ms/step - loss: 2.7851 - acc: 0.4906 - val_loss: 4.5522 - val_acc: 0.4064\n","Epoch 7/30\n","50/50 [==============================] - 15s 305ms/step - loss: 2.5476 - acc: 0.5129 - val_loss: 4.5665 - val_acc: 0.4309\n","Epoch 8/30\n","50/50 [==============================] - 15s 303ms/step - loss: 2.3197 - acc: 0.5344 - val_loss: 4.6825 - val_acc: 0.4272\n","Epoch 9/30\n","50/50 [==============================] - 15s 294ms/step - loss: 2.1161 - acc: 0.5556 - val_loss: 4.4603 - val_acc: 0.4480\n","Epoch 10/30\n","50/50 [==============================] - 15s 296ms/step - loss: 1.9251 - acc: 0.5828 - val_loss: 4.6044 - val_acc: 0.4509\n","Epoch 11/30\n","50/50 [==============================] - 16s 311ms/step - loss: 1.7456 - acc: 0.6100 - val_loss: 4.7457 - val_acc: 0.4472\n","Epoch 12/30\n","50/50 [==============================] - 15s 303ms/step - loss: 1.5894 - acc: 0.6332 - val_loss: 4.8408 - val_acc: 0.4426\n","Epoch 13/30\n","50/50 [==============================] - 15s 296ms/step - loss: 1.4380 - acc: 0.6626 - val_loss: 4.7526 - val_acc: 0.4459\n","Epoch 14/30\n","50/50 [==============================] - 15s 294ms/step - loss: 1.3052 - acc: 0.6862 - val_loss: 4.8945 - val_acc: 0.4407\n","Epoch 15/30\n","50/50 [==============================] - 16s 315ms/step - loss: 1.1920 - acc: 0.7038 - val_loss: 4.8427 - val_acc: 0.4466\n","Epoch 16/30\n","50/50 [==============================] - 15s 305ms/step - loss: 1.0838 - acc: 0.7271 - val_loss: 4.9578 - val_acc: 0.4462\n","Epoch 17/30\n","50/50 [==============================] - 15s 292ms/step - loss: 0.9792 - acc: 0.7530 - val_loss: 5.0361 - val_acc: 0.4403\n","Epoch 18/30\n","50/50 [==============================] - 15s 292ms/step - loss: 0.8881 - acc: 0.7712 - val_loss: 4.9572 - val_acc: 0.4504\n","Epoch 19/30\n","50/50 [==============================] - 16s 319ms/step - loss: 0.8095 - acc: 0.7950 - val_loss: 5.0101 - val_acc: 0.4495\n","Epoch 20/30\n","50/50 [==============================] - 15s 297ms/step - loss: 0.7364 - acc: 0.8127 - val_loss: 5.1018 - val_acc: 0.4486\n","Epoch 21/30\n","50/50 [==============================] - 15s 304ms/step - loss: 0.6725 - acc: 0.8242 - val_loss: 5.1972 - val_acc: 0.4518\n","Epoch 22/30\n","50/50 [==============================] - 15s 295ms/step - loss: 0.6163 - acc: 0.8361 - val_loss: 5.2153 - val_acc: 0.4527\n","Epoch 23/30\n","50/50 [==============================] - 16s 312ms/step - loss: 0.5653 - acc: 0.8484 - val_loss: 5.2070 - val_acc: 0.4530\n","Epoch 24/30\n","50/50 [==============================] - 15s 299ms/step - loss: 0.5147 - acc: 0.8565 - val_loss: 5.2155 - val_acc: 0.4501\n","Epoch 25/30\n","50/50 [==============================] - 15s 308ms/step - loss: 0.4743 - acc: 0.8673 - val_loss: 5.3158 - val_acc: 0.4491\n","Epoch 26/30\n","50/50 [==============================] - 15s 294ms/step - loss: 0.4401 - acc: 0.8738 - val_loss: 5.3848 - val_acc: 0.4494\n","Epoch 27/30\n","50/50 [==============================] - 15s 301ms/step - loss: 0.4058 - acc: 0.8802 - val_loss: 5.3149 - val_acc: 0.4560\n","Epoch 28/30\n","50/50 [==============================] - 15s 296ms/step - loss: 0.3767 - acc: 0.8863 - val_loss: 5.3416 - val_acc: 0.4510\n","Epoch 29/30\n","50/50 [==============================] - 15s 303ms/step - loss: 0.3569 - acc: 0.8890 - val_loss: 5.4909 - val_acc: 0.4473\n","Epoch 30/30\n","50/50 [==============================] - 15s 294ms/step - loss: 0.3348 - acc: 0.8915 - val_loss: 5.5232 - val_acc: 0.4520\n"]}],"source":["r = model.fit(\n","  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n","  batch_size=BATCH_SIZE,\n","  epochs=EPOCHS,\n","  validation_split=0.2\n",")"]},{"cell_type":"markdown","metadata":{"id":"jskuFuaU5QtH"},"source":["# **Salvar modelo treinado no Google Drive para re-importá-lo futuramente (ou baixá-lo no ambiente offline)**\n","\n","Aqui, forneça o mesmo endereço da pasta na qual os arquivos das bases de dados foram salvos. Assim, o modelo ficará salvo na mesma pasta, facilitando sua localização."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28aBSXWa59ww"},"outputs":[],"source":["folder_adress = \"/content/drive/MyDrive/Coisas úteis separadas para a Paula/Deep Learning - Advanced NLP and RNNs/Lesson 6 - Attention/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAyummsK5g27"},"outputs":[],"source":["from keras.models import load_model\n","#Definicao do endereço e nome do novo arquivo:\n","\n","file_address = folder_adress + \"rnn1_attention_obtained_model.h5\"\n","#file_address armazena o local em que sera salvo o modelo: o endereço da pasta foi concatenado\n","#ao nome e extensão desejados para o arquivo.\n","#note que o arquivo gerado se chama obtained_model.h5\n","#Em Keras, os modelos devem ser salvos com a extensão h5.\n","\n","#Salvar modelo\n","model.save(\"attention_model_PortugueseToEnglish.h5\")\n","\n","\n","#Modelos Scikit-learn: use o modelo da biblioteca dill:\n","#import dill\n","#dill.dump(model, open(file_address, 'wb'))\n","#Nosso modelo foi gerado com a denominação \"model\", como vimos acima.\n","#aqui, modifique \"model\" pelo nome do modelo declarado, caso seja outro o nome utilizado\n","#note que o arquivo gerado se chama obtained_model.dill\n","#o dill permite salvar em qualquer extensao (pkl, sav, pmml, ...)"]},{"cell_type":"markdown","metadata":{"id":"lHxSHZ4Q6_qv"},"source":["# **Reimportar modelo pré-treinado**\n","\n","Para reimportar o modelo, basta seguir o código abaixo (ajuste-o de acordo com a pasta do drive na qual está salvo o modelo obtido anteriormente) - basta substituir o valor de \"file_address\" pelo endereço correto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ct-qKMQJ-K5F"},"outputs":[],"source":["from keras.models import load_model\n","file_address = \"/content/drive/MyDrive/Coisas úteis separadas para a Paula/Deep Learning - Advanced NLP and RNNs/Lesson 6 - Attention/rnn1_attention_obtained_model.h5\"\n","\n","model = load_model(file_address)\n","\n","\n","#Em Sckit-learn\n","#import dill\n","#loaded_model = dill.load(open(file_address, 'rb'))\n","#Agora o modelo carregado  recebe o nome de loaded_model\n","#todos os campos que recebiam o nome do modelo devem ter o nome substituído para loaded_model\n","#você também pode modificar o nome loaded_model para um nome de seu interesse. Por exemplo:\n","#model = dill.load(open(file_address, 'rb')) fará o modelo ser carregado com o nome model\n","\n","#ATENÇÃO: Caso já haja um modelo 1 com o nome escolhido para carregar este modelo 2, o modelo 1 deixará de existir, \n","#sendo substituído pelo modelo 2 carregado."]},{"cell_type":"markdown","metadata":{"id":"2v8Euvqm_YQl"},"source":["# **Plotar gráfico da função de perda**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"aTqvbIRw_eZj","outputId":"7ba70d51-b534-4b27-f4fe-6df78fd6466b"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plot some data\n","plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FOrLhLRwHWL_"},"source":["O descolamento das curvas indica certo grau de overfitting do modelo.\n","- Isto pode ter sido causado por um número reduzido de dados de treinamento, já que limitamos as amostras pela definição do hiperparâmetro `NUM_SAMPLES = 10000`."]},{"cell_type":"markdown","metadata":{"id":"p8p5OygY_iaU"},"source":["# **Plotar gráfico da precisão**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"Ss9D42nE_rsb","outputId":"ba6cfe3d-d04d-41ee-8e39-78afa7129030"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# accuracies\n","plt.plot(r.history['acc'], label='acc')\n","plt.plot(r.history['val_acc'], label='val_acc')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gEXQKKyNf_Af"},"source":["# **Construção do segundo modelo para o decoder**\n","\n","Em Keras, precisamos especificar também os comprimentos das sequências ou séries temporais.\n","- Para o treinamento, o tamanho do input será simplesmente o comprimento da sequência mais longa a ser processada.\n","  - No treinamento (sistema encoder), nós alimentamos a rede com a sequência de input (frase) completa, e obtemos uma previsão para a palavra seguinte - tudo isto ocorre simultaneamente.\n","- Para os testes e previsões (sistema decoder), o tamanho do input é diferente. Nós só podemos passar uma palavra por vez, pois precisamos usar cada previsão como input da unidade recursiva seguinte.\n","  - Precisamos, então, construir um novo modelo, com novas entradas e novos tamanhos.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzcydGM9Lg8F"},"outputs":[],"source":["##### Make predictions #####\n","# As with the poetry example, we need to create another model\n","# that can take in the RNN state and previous word as input\n","# and accept a T=1 sequence.\n","\n","# The encoder will be stand-alone\n","# From this we will get our initial decoder hidden state\n","# i.e. h(1), ..., h(Tx)\n","encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)"]},{"cell_type":"markdown","metadata":{"id":"wLQT-oGRX_2M"},"source":["# **Saída do modelo**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pbsaivydm83Z"},"outputs":[],"source":["# next we define a T=1 decoder model\n","encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n","\n","# no need to loop over attention steps this time because there is only one step\n","context = one_step_attention(encoder_outputs_as_input, initial_s)\n","\n","# combine context with last word\n","decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n","\n","# lstm and final dense\n","o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n","decoder_outputs = decoder_dense(o)\n","\n","# note: we don't really need the final stack and tranpose\n","# because there's only 1 output\n","# it is already of size N x D\n","# no need to make it 1 x N x D --> N x 1 x D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JJljOPNZ76L"},"outputs":[],"source":["# create the model object\n","decoder_model = Model(\n","  inputs=[\n","    decoder_inputs_single,\n","    encoder_outputs_as_input,\n","    initial_s, \n","    initial_c\n","  ],\n","  outputs=[decoder_outputs, s, c]\n",")"]},{"cell_type":"markdown","metadata":{"id":"lU_d1WuJ93K_"},"source":["O modelo de redes neurais retornará apenas valores numéricos, os quais correpondem aos índices das palavras. \n","- Precisamos, portanto, criar um mapeamento índice-palavras (i.e., informar a quais palavras correspondem cada um dos índices retornados).\n","- Isto permitirá que o modelo retorne sequências contendo palavras (sentenças).\n","\n","### **O dicionário `idx2word_trans`, portanto, correlaciona os índices numéricos a cada uma das possíveis palavras de saída traduzidas (translated)**.\n","\n","Assim, após as redes neurais retornarem um valor numérico, o algoritmo acessará este dicionário para coletar a palavra seguinte da sentença gerada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9l7bPLNmz04"},"outputs":[],"source":["# map indexes back into real words\n","# so we can view the results\n","idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n","idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"]},{"cell_type":"markdown","metadata":{"id":"aoAkuuv9J1om"},"source":["# **Função `decode_sequence`**\n","\n","Esta função gerará a sentença traduzida, dada uma sentença de input."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wgPjRf_3nDAe"},"outputs":[],"source":["def decode_sequence(input_seq):\n","  # Encode the input as state vectors.\n","  enc_out = encoder_model.predict(input_seq)\n","\n","  # Generate empty target sequence of length 1.\n","  target_seq = np.zeros((1, 1))\n","  \n","  # Populate the first character of target sequence with the start character.\n","  # NOTE: tokenizer lower-cases all words\n","  target_seq[0, 0] = word2idx_outputs['<sos>']\n","\n","  # if we get this we break\n","  eos = word2idx_outputs['<eos>']\n","\n","\n","  # [s, c] will be updated in each loop iteration\n","  s = np.zeros((1, LATENT_DIM_DECODER))\n","  c = np.zeros((1, LATENT_DIM_DECODER))\n","\n","\n","  # Create the translation\n","  output_sentence = []\n","  for _ in range(max_len_target):\n","    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n","        \n","\n","    # Get next word\n","    idx = np.argmax(o.flatten())\n","\n","    # End sentence of EOS\n","    if eos == idx:\n","      break\n","\n","    word = ''\n","    if idx > 0:\n","      word = idx2word_trans[idx]\n","      output_sentence.append(word)\n","\n","    # Update the decoder input\n","    # which is just the word just generated\n","    target_seq[0, 0] = idx\n","\n","  return ' '.join(output_sentence)"]},{"cell_type":"markdown","metadata":{"id":"rCphBJfuumJd"},"source":["### **Uma diferença importante em relação ao language modelling é que aqui nós tomamos o máximo de probabilidade, ao invés de tomar um valor da distribuição estatística das frases possíveis**.\n","- Isso porque desejamos a tradução mais precisa possível, não um novo poema."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJCSLyDanGeV","outputId":"7700816e-3908-4813-e0b4-314d1711fb77"},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Eu vim sozinho.\n","Predicted translation: i am win.\n","Actual translation: I came alone. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Coma devagar.\n","Predicted translation: eat slowly.\n","Actual translation: Eat slowly. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Vocês têm 18 anos?\n","Predicted translation: are you 18?\n","Actual translation: Are you 18? <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Nós entraremos.\n","Predicted translation: we agree.\n","Actual translation: We'll go in. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Tom acenou com a cabeça.\n","Predicted translation: tom nodded.\n","Actual translation: Tom nodded. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Que fome!\n","Predicted translation: i i hungry!\n","Actual translation: Am I hungry! <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Ignore-as.\n","Predicted translation: ignore them.\n","Actual translation: Ignore them. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Te cuida!\n","Predicted translation: take care!\n","Actual translation: Take care! <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Tom bebe.\n","Predicted translation: tom drinks. tom.\n","Actual translation: Tom drinks. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Eu estou feliz.\n","Predicted translation: i am happy.\n","Actual translation: I am happy. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Ela bateu nele.\n","Predicted translation: she hit him.\n","Actual translation: She hit him. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: É seu?\n","Predicted translation: is it yours?\n","Actual translation: Is it yours? <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] y\n"]},{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: Tom bebe.\n","Predicted translation: tom drinks. tom.\n","Actual translation: Tom drinks. <eos>\n"]},{"name":"stdin","output_type":"stream","text":["Continue? [Y/n] n\n"]}],"source":["while True:\n","  # Do some test translations\n","  i = np.random.choice(len(input_texts))\n","  input_seq = encoder_inputs[i:i+1]\n","  translation = decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:', input_texts[i])\n","  print('Predicted translation:', translation)\n","  print('Actual translation:', target_texts[i])\n","\n","  ans = input(\"Continue? [Y/n]\")\n","  if ans and ans.lower().startswith('n'):\n","    break"]},{"cell_type":"markdown","metadata":{"id":"tOHHwzDCEpla"},"source":["# **NOTA: Realizar previsões com o modelo**\n","\n","Note que o comando `model.predict(X)` calcula os valores previstos pelo modelo `model` para cada um dos valores do dataframe `X` fornecido como input."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Attention_rnn_2_translatePortugueseToEnglish_NLP_GColab.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (Data Science)","language":"python","name":"python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}